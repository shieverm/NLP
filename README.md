
.ipynb involves below :
Corpus link :
https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpusLinks

1. Load the dataset and perform the preprocessing steps. We are using a Class that would convert every sentence with its named entities (tags) into a list of tuples and plot the distribution of the sentence lengths in the dataset. 
2. Creation of word-to-index and index-to-word mapping which is necessary for conversions for words before training and after prediction.
3. From the list of tuples generated earlier, now we will build the independent and dependent variable structure.
4.Splitting the data: Training and Testing.
5.Build a neural network (LSTM) for NER using two different embedding methods.  
  -BERT Embeddings
  -FastText Embeddings


 6. Evaluate the performance of two models. 
 6. Visualize the final output as a graph etc. 


https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/Links to an external site.
https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a
